import cv2
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import datetime
import os

# Charger le classificateur Haar cascade
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

if face_cascade.empty():
    st.error("Erreur : le fichier Haar cascade n'a pas √©t√© charg√© ! V√©rifie le chemin.")

# Cr√©er un dossier pour sauvegarder les images si n√©cessaire
save_dir = "saved_faces"
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

st.title("üëÄ Face Detection with Viola-Jones (Streamlit + WebRTC)")
st.markdown("""
**Instructions :**  
1. Autorisez l'acc√®s √† votre webcam.  
2. Ajustez les param√®tres dans la barre lat√©rale.  
3. Les visages seront d√©tect√©s en temps r√©el.  
4. Activez l'option pour sauvegarder les visages d√©tect√©s.  
""")

# Param√®tres ajustables
st.sidebar.header("‚öôÔ∏è Param√®tres de d√©tection")
scale_factor = st.sidebar.slider("Param√®tre scaleFactor", 1.01, 2.0, 1.3, 0.01)
min_neighbors = st.sidebar.slider("Param√®tre minNeighbors", 1, 10, 5)
rect_color_hex = st.sidebar.color_picker("Couleur des rectangles", "#00FF00")
save_images = st.sidebar.checkbox("üíæ Sauvegarder les visages d√©tect√©s")

# Conversion couleur HEX ‚Üí BGR
hex_color = rect_color_hex.lstrip('#')
rect_color_bgr = tuple(int(hex_color[i:i+2], 16) for i in (4, 2, 0))

# Compteur global (stock√© dans la session Streamlit)
if "total_faces_detected" not in st.session_state:
    st.session_state.total_faces_detected = 0

# D√©finir le transformateur vid√©o
class FaceDetectionTransformer(VideoTransformerBase):
    def __init__(self):
        self.face_counter = 0

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")

        # Am√©liorer le contraste
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        gray = cv2.equalizeHist(gray)

        # D√©tection des visages
        faces = face_cascade.detectMultiScale(
            gray,
            scaleFactor=scale_factor,
            minNeighbors=min_neighbors,
            minSize=(50, 50)
        )

        for i, (x, y, w, h) in enumerate(faces):
            cv2.rectangle(img, (x, y), (x + w, y + h), rect_color_bgr, 2)

            if save_images:
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = os.path.join(save_dir, f"face_{timestamp}_{i}.jpg")
                cv2.imwrite(filename, img[y:y+h, x:x+w])

        # ‚ûï Mise √† jour du compteur global
        st.session_state.total_faces_detected += len(faces)

        return img

# Lancer le flux WebRTC
webrtc_streamer(
    key="face-detection",
    video_transformer_factory=FaceDetectionTransformer
)

# Afficher le compteur total
st.markdown(f"### üë§ Nombre total de visages d√©tect√©s pendant la session : **{st.session_state.total_faces_detected}**")
